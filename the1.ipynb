{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPSILON = 10**(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.asarray(Image.open('dataset/support_96/Acadian_Flycatcher_0016_887710060.jpg'))\n",
    "img2 = np.asarray(Image.open('dataset/query_1/Acadian_Flycatcher_0016_887710060.jpg'))\n",
    "img3 = np.asarray(Image.open('dataset/query_1/American_Crow_0024_2618947526.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histogram_by_grids(img, interval=1, grid_count=1):\n",
    "    x, y = img.shape[0], img.shape[1]\n",
    "    grid_size = img.shape[0]//grid_count\n",
    "    histogram_list = np.zeros(0)\n",
    "    for i in range(grid_count):\n",
    "        for j in range(grid_count):\n",
    "            img_slice = img[i*grid_size:(i+1)*grid_size,j*grid_size:(j+1)*grid_size]\n",
    "            slice_hist = per_channel_histogram(img_slice, interval)\n",
    "            normalized_hist = {'red':normalize_histogram(slice_hist['red']), 'green':normalize_histogram(slice_hist['green']), 'blue':normalize_histogram(slice_hist['blue'])}\n",
    "            histogram_list = np.append(histogram_list, normalized_hist)\n",
    "    return histogram_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_channel_histogram(img, interval=1):\n",
    "    x , y = img.shape[0], img.shape[1]\n",
    "    \n",
    "    histograms = {\n",
    "        'red':np.zeros(256, np.int16), \n",
    "        'green':np.zeros(256, np.int16), \n",
    "        'blue':np.zeros(256, np.int16)\n",
    "        }\n",
    "\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            histograms['red'][img[i][j][0]] += 1\n",
    "            histograms['green'][img[i][j][1]] += 1\n",
    "            histograms['blue'][img[i][j][2]] += 1\n",
    "\n",
    "    if interval == 1:\n",
    "        return histograms\n",
    "    \n",
    "    bin_num = 256 // interval\n",
    "    \n",
    "    new_histograms = {\n",
    "        'red':np.zeros(bin_num, np.int16), \n",
    "        'green':np.zeros(bin_num, np.int16), \n",
    "        'blue':np.zeros(bin_num, np.int16)\n",
    "        }\n",
    "\n",
    "    for i in range(bin_num):\n",
    "        for j in range(interval):\n",
    "            new_histograms['red'][i] += histograms['red'][i * interval + j]\n",
    "            new_histograms['green'][i] += histograms['green'][i * interval + j]\n",
    "            new_histograms['blue'][i] += histograms['blue'][i * interval + j]\n",
    "\n",
    "    return new_histograms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_histogram(h):\n",
    "    norm = np.sum(h)\n",
    "    normalized_hist = np.divide(h,np.sum(h))\n",
    "    normalized_hist[normalized_hist==0] = EPSILON / norm\n",
    "    return normalized_hist\n",
    "\n",
    "def kl_divergence(query_hist, support_hist):\n",
    "    division = np.divide(query_hist, support_hist)\n",
    "    log_div = np.log2(division)\n",
    "    h_mult = np.multiply(query_hist, log_div)\n",
    "    divergence = np.sum(h_mult)\n",
    "    return divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence_by_grids(query_hist_list, support_hist_list):\n",
    "    divergence_array = np.zeros(0)\n",
    "    hist_count = query_hist_list.shape[0]\n",
    "    for qh,sh in zip(query_hist_list, support_hist_list):\n",
    "        divergence = kl_divergence(qh['red'], sh['red']) + kl_divergence(qh['green'], sh['green']) + kl_divergence(qh['blue'], sh['blue'])\n",
    "        divergence_array = np.append(divergence_array, divergence)\n",
    "    return np.average(divergence_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.6115735352295\n"
     ]
    }
   ],
   "source": [
    "test = kl_divergence_by_grids(get_histogram_by_grids(img1, grid_count=12), get_histogram_by_grids(img2, grid_count=12))\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3801293466459518\n"
     ]
    }
   ],
   "source": [
    "hist1 = per_channel_histogram(img1)\n",
    "hist2 = per_channel_histogram(img2)\n",
    "red = kl_divergence(normalize_histogram(hist1['red']), normalize_histogram(hist2['red']))\n",
    "print(red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Images\n",
    "support_filenames = next(walk('dataset/support_96'), (None, None, []))[2]\n",
    "query_1_filenames = next(walk('dataset/query_1'), (None, None, []))[2]\n",
    "query_2_filenames = next(walk('dataset/query_2'), (None, None, []))[2]\n",
    "query_3_filenames = next(walk('dataset/query_3'), (None, None, []))[2]\n",
    "\n",
    "support_images = []\n",
    "for filename in support_filenames:\n",
    "    with Image.open('dataset/support_96/{}'.format(filename)) as image:\n",
    "        support_images.append((filename, np.asarray(image)))\n",
    "\n",
    "query_1_images = []\n",
    "for filename in query_1_filenames:\n",
    "    with Image.open('dataset/query_1/{}'.format(filename)) as image:\n",
    "        query_1_images.append((filename, np.asarray(image)))\n",
    "query_2_images = []\n",
    "for filename in query_2_filenames:\n",
    "    with Image.open('dataset/query_2/{}'.format(filename)) as image:\n",
    "        query_2_images.append((filename, np.asarray(image)))\n",
    "\n",
    "query_3_images = []\n",
    "for filename in query_3_filenames:\n",
    "    with Image.open('dataset/query_3/{}'.format(filename)) as image:\n",
    "        query_3_images.append((filename, np.asarray(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:27<00:00,  7.38it/s]\n",
      "100%|██████████| 200/200 [00:24<00:00,  8.27it/s]\n",
      "100%|██████████| 200/200 [00:32<00:00,  6.10it/s]\n",
      "100%|██████████| 200/200 [00:28<00:00,  7.10it/s]\n",
      "100%|██████████| 200/200 [00:46<00:00,  4.28it/s]\n",
      "100%|██████████| 200/200 [00:48<00:00,  4.14it/s]\n",
      "100%|██████████| 200/200 [03:18<00:00,  1.01it/s]\n",
      "100%|██████████| 200/200 [02:59<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "grid_counts = [12, 16, 24, 48]\n",
    "histogram_list_by_grids = {}\n",
    "for grid_count in grid_counts:\n",
    "    support_query_1_hist_lists = {'support_histograms':[], 'query_histograms':[]}\n",
    "    support_query_2_hist_lists = {'support_histograms':[], 'query_histograms':[]}\n",
    "    support_query_3_hist_lists = {'support_histograms':[], 'query_histograms':[]}\n",
    "    # get histograms of query 1\n",
    "    interval = 8 # best for query 1\n",
    "    # for name, img in tqdm(support_images):\n",
    "    #     hist_list = get_histogram_by_grids(img, interval=interval, grid_count=grid_count)\n",
    "    #     support_query_1_hist_lists['support_histograms'].append((name, hist_list))\n",
    "    \n",
    "    # for name, img in tqdm(query_1_images):\n",
    "    #     hist_list = get_histogram_by_grids(img, interval=interval, grid_count=grid_count)\n",
    "    #     support_query_1_hist_lists['query_histograms'].append((name, hist_list))\n",
    "    \n",
    "    # # get histograms of query 2\n",
    "    # interval = 16 # best for query 2\n",
    "    # for name, img in tqdm(support_images):\n",
    "    #     hist_list = get_histogram_by_grids(img, interval=interval, grid_count=grid_count)\n",
    "    #     support_query_2_hist_lists['support_histograms'].append((name, hist_list))\n",
    "    \n",
    "    # for name, img in tqdm(query_2_images):\n",
    "    #     hist_list = get_histogram_by_grids(img, interval=interval, grid_count=grid_count)\n",
    "    #     support_query_2_hist_lists['query_histograms'].append((name, hist_list))\n",
    "    \n",
    "    # get histograms of query 3\n",
    "    interval = 32 # best for query 3\n",
    "    for name, img in tqdm(support_images):\n",
    "        hist_list = get_histogram_by_grids(img, interval=interval, grid_count=grid_count)\n",
    "        support_query_3_hist_lists['support_histograms'].append((name, hist_list))\n",
    "    \n",
    "    for name, img in tqdm(query_3_images):\n",
    "        hist_list = get_histogram_by_grids(img, interval=interval, grid_count=grid_count)\n",
    "        support_query_3_hist_lists['query_histograms'].append((name, hist_list))\n",
    "\n",
    "    histogram_list_by_grids[grid_count] = {'q1':support_query_1_hist_lists, 'q2':support_query_2_hist_lists, 'q3':support_query_3_hist_lists}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:43<00:00,  1.22it/s]\n",
      "100%|██████████| 200/200 [04:43<00:00,  1.42s/it]\n",
      "100%|██████████| 200/200 [09:46<00:00,  2.93s/it]\n",
      "100%|██████████| 200/200 [49:10<00:00, 14.75s/it]\n"
     ]
    }
   ],
   "source": [
    "# query 1 spatial grids\n",
    "query_1_results_by_grids = {}\n",
    "for grid_count in grid_counts:\n",
    "    correct_guesses = 0\n",
    "    support_hist_list = histogram_list_by_grids[grid_count]['q1']['support_histograms']\n",
    "    query_hist_list = histogram_list_by_grids[grid_count]['q1']['query_histograms']\n",
    "    for name, support_hist in tqdm(support_hist_list):\n",
    "        min_divergence = 999999\n",
    "        for q_name, query_hist in query_hist_list:\n",
    "            divergence = kl_divergence_by_grids(query_hist, support_hist)\n",
    "            if divergence < min_divergence:\n",
    "                min_divergence = divergence\n",
    "                result = {'support': name, 'query': q_name, 'divergence': divergence}\n",
    "        if result['support'] == result['query']:\n",
    "            correct_guesses += 1\n",
    "    query_1_results_by_grids[f\"Grid_count: {grid_count}\"] = correct_guesses / 200\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_1_results_by_grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:49<00:00,  1.83it/s]\n",
      "100%|██████████| 200/200 [03:13<00:00,  1.04it/s]\n",
      "100%|██████████| 200/200 [08:15<00:00,  2.48s/it]\n",
      "100%|██████████| 200/200 [39:57<00:00, 11.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Grid_count: 12': 0.215, 'Grid_count: 16': 0.22, 'Grid_count: 24': 0.25, 'Grid_count: 48': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# query 2 spatial grids\n",
    "query_2_results_by_grids = {}\n",
    "for grid_count in grid_counts:\n",
    "    correct_guesses = 0\n",
    "    support_hist_list = histogram_list_by_grids[grid_count]['q2']['support_histograms']\n",
    "    query_hist_list = histogram_list_by_grids[grid_count]['q2']['query_histograms']\n",
    "    for name, support_hist in tqdm(support_hist_list):\n",
    "        min_divergence = 999999\n",
    "        for q_name, query_hist in query_hist_list:\n",
    "            divergence = kl_divergence_by_grids(query_hist, support_hist)\n",
    "            if divergence < min_divergence:\n",
    "                min_divergence = divergence\n",
    "                result = {'support': name, 'query': q_name, 'divergence': divergence}\n",
    "        if result['support'] == result['query']:\n",
    "            correct_guesses += 1\n",
    "    query_2_results_by_grids[f\"Grid_count: {grid_count}\"] = correct_guesses / 200\n",
    "\n",
    "print(query_2_results_by_grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wuhuu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:35<00:00,  1.29it/s]\n",
      "100%|██████████| 200/200 [04:40<00:00,  1.40s/it]\n",
      "100%|██████████| 200/200 [10:20<00:00,  3.10s/it]\n",
      "100%|██████████| 200/200 [36:28<00:00, 10.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Grid_count: 12': 0.405, 'Grid_count: 16': 0.445, 'Grid_count: 24': 0.495, 'Grid_count: 48': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# query 3 spatial grids\n",
    "query_3_results_by_grids = {}\n",
    "print(\"wuhuu\")\n",
    "for grid_count in grid_counts:\n",
    "    correct_guesses = 0\n",
    "    support_hist_list = histogram_list_by_grids[grid_count]['q3']['support_histograms']\n",
    "    query_hist_list = histogram_list_by_grids[grid_count]['q3']['query_histograms']\n",
    "    for name, support_hist in tqdm(support_hist_list):\n",
    "        min_divergence = 999999\n",
    "        for q_name, query_hist in query_hist_list:\n",
    "            divergence = kl_divergence_by_grids(query_hist, support_hist)\n",
    "            if divergence < min_divergence:\n",
    "                min_divergence = divergence\n",
    "                result = {'support': name, 'query': q_name, 'divergence': divergence}\n",
    "        if result['support'] == result['query']:\n",
    "            correct_guesses += 1\n",
    "    query_3_results_by_grids[f\"Grid_count: {grid_count}\"] = correct_guesses / 200\n",
    "\n",
    "print(query_3_results_by_grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:27<00:00, 53.55s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get Histograms into dict\n",
    "intervals = [4, 8, 16, 32, 64]\n",
    "interval_histogram_dict = {}\n",
    "for q in tqdm(intervals):      \n",
    "    support_histograms = []\n",
    "    query_1_histograms = []\n",
    "    query_2_histograms = []\n",
    "    query_3_histograms = []\n",
    "    for name, img in support_images:\n",
    "        hist = per_channel_histogram(img, q)\n",
    "        support_histograms.append((name, (normalize_histogram(hist['red']),normalize_histogram(hist['green']), normalize_histogram(hist['blue']))))\n",
    "    \n",
    "    for name, img in query_1_images:\n",
    "        hist = per_channel_histogram(img, q)\n",
    "        query_1_histograms.append((name, (normalize_histogram(hist['red']),normalize_histogram(hist['green']), normalize_histogram(hist['blue']))))\n",
    "    \n",
    "    for name, img in query_2_images:\n",
    "        hist = per_channel_histogram(img, q)\n",
    "        query_2_histograms.append((name, (normalize_histogram(hist['red']),normalize_histogram(hist['green']), normalize_histogram(hist['blue']))))\n",
    "    \n",
    "    for name, img in query_3_images:\n",
    "        hist = per_channel_histogram(img, q)\n",
    "        query_3_histograms.append((name, (normalize_histogram(hist['red']),normalize_histogram(hist['green']), normalize_histogram(hist['blue']))))\n",
    "    \n",
    "    interval_histogram_dict[q] = {'sup': support_histograms, 'query_1':query_1_histograms, 'query_2':query_2_histograms, 'query_3':query_3_histograms}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 118.36it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 243.31it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 258.59it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 250.59it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 261.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#q3 results\n",
    "q3_min_results = []\n",
    "intervals = [4, 8, 16, 32, 64]\n",
    "q3_accuracies = []\n",
    "for q in interval_histogram_dict.keys():\n",
    "    correct_guesses = 0\n",
    "    for name, hist in tqdm(interval_histogram_dict[q]['sup']):\n",
    "        min_divergence = 99\n",
    "        for q_name, q_hist in interval_histogram_dict[q]['query_3']:\n",
    "            red_divergence = kl_divergence(q_hist[0], hist[0])\n",
    "            green_divergence = kl_divergence(q_hist[1], hist[1])\n",
    "            blue_divergence = kl_divergence(q_hist[2], hist[2])\n",
    "            divergence = (red_divergence + blue_divergence + blue_divergence) / 3\n",
    "            if divergence < min_divergence:\n",
    "                min_divergence = divergence\n",
    "                result = {'support': name, 'query': q_name, 'divergence': divergence}\n",
    "        q3_min_results.append(result)\n",
    "        if result['support'] == result['query']:\n",
    "            correct_guesses += 1\n",
    "    q3_accuracies.append({'interval': q, 'acc': correct_guesses / 200})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'interval': 4, 'acc': 0.2},\n",
       " {'interval': 8, 'acc': 0.2},\n",
       " {'interval': 16, 'acc': 0.21},\n",
       " {'interval': 32, 'acc': 0.21},\n",
       " {'interval': 64, 'acc': 0.19}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 221.70it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 246.35it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 257.68it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 262.80it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 240.06it/s]\n"
     ]
    }
   ],
   "source": [
    "#q2 results\n",
    "q2_min_results = []\n",
    "intervals = [4, 8, 16, 32, 64]\n",
    "q2_accuracies = []\n",
    "for q in interval_histogram_dict.keys():\n",
    "    correct_guesses = 0\n",
    "    for name, hist in tqdm(interval_histogram_dict[q]['sup']):\n",
    "        min_divergence = 99\n",
    "        for q_name, q_hist in interval_histogram_dict[q]['query_2']:\n",
    "            red_divergence = kl_divergence(q_hist[0], hist[0])\n",
    "            green_divergence = kl_divergence(q_hist[1], hist[1])\n",
    "            blue_divergence = kl_divergence(q_hist[2], hist[2])\n",
    "            divergence = (red_divergence + blue_divergence + blue_divergence) / 3\n",
    "            if divergence < min_divergence:\n",
    "                min_divergence = divergence\n",
    "                result = {'support': name, 'query': q_name, 'divergence': divergence}\n",
    "        q2_min_results.append(result)\n",
    "        if result['support'] == result['query']:\n",
    "            correct_guesses += 1\n",
    "    q2_accuracies.append({'interval': q, 'acc': correct_guesses / 200})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'interval': 4, 'acc': 1.0},\n",
       " {'interval': 8, 'acc': 1.0},\n",
       " {'interval': 16, 'acc': 1.0},\n",
       " {'interval': 32, 'acc': 1.0},\n",
       " {'interval': 64, 'acc': 1.0}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 223.70it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 234.45it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 248.62it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 248.41it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 143.00it/s]\n"
     ]
    }
   ],
   "source": [
    "#q1 results\n",
    "q1_min_results = []\n",
    "intervals = [4, 8, 16, 32, 64]\n",
    "q1_accuracies = []\n",
    "for q in interval_histogram_dict.keys():\n",
    "    correct_guesses = 0\n",
    "    for name, hist in tqdm(interval_histogram_dict[q]['sup']):\n",
    "        min_divergence = 99\n",
    "        for q_name, q_hist in interval_histogram_dict[q]['query_1']:\n",
    "            red_divergence = kl_divergence(q_hist[0], hist[0])\n",
    "            green_divergence = kl_divergence(q_hist[1], hist[1])\n",
    "            blue_divergence = kl_divergence(q_hist[2], hist[2])\n",
    "            divergence = (red_divergence + blue_divergence + blue_divergence) / 3\n",
    "            if divergence < min_divergence:\n",
    "                min_divergence = divergence\n",
    "                result = {'support': name, 'query': q_name, 'divergence': divergence}\n",
    "        q1_min_results.append(result)\n",
    "        if result['support'] == result['query']:\n",
    "            correct_guesses += 1\n",
    "    q1_accuracies.append({'interval': q, 'acc': correct_guesses / 200})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'interval': 4, 'acc': 0.98},\n",
       " {'interval': 8, 'acc': 0.98},\n",
       " {'interval': 16, 'acc': 0.97},\n",
       " {'interval': 32, 'acc': 0.96},\n",
       " {'interval': 64, 'acc': 0.9}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_accuracies"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
